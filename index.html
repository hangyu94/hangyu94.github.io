<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Hangyu Li, 李航宇, Image Processing, Deep Learning, Affective Computing, Xidian University">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/favicon1.ico">
<title>Hangyu Li</title>
</head>
 
 
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/证件照_蓝底.jpg" alt="" height="215px" /></a>&nbsp;</td></td></td></td>
<td align="left"><p><a href="./"><font size="4">Hangyu Li (</font><font size="4"; font style="font-family:Microsoft YaHei">李航宇</font><font size="4">)</font></a><br />
<i>Ph.D. Student </i>
<br /><br />
<a href="https://isn.xidian.edu.cn/" target="_blank">State Key Laboratory of Integrated Services Networks</a><br />
<a href="https://www.xidian.edu.cn/" target="_blank">Xidian University</a><br />
<br />
Location: No. 2 South Taibai Road, Xi'an, Shaanxi, China<br />
<class="staffshortcut">
 <A HREF="#News">News</A> | 
 <A HREF="#Interest">Research Interest</A> | 
 <A HREF="#Education">Education</A> | 
 <A HREF="#Publications">Publications</A> | 
 <A HREF="#Services">Services</A>
<br />
<br />
 
Email: hangyuli.xidian@gmail.com (prior); &nbsp;&nbsp;&nbsp;&nbsp; hyli_94@stu.xidian.edu.cn <br />
[<a href="https://scholar.google.com/citations?user=I0lFuJEAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>] 
[<a href="https://github.com/hangyu94" target="_blank">GitHub</a>] 
[<a href="https://www.researchgate.net/profile/Hangyu-Li-6" target="_blank">ResearchGate</a>]
</td></tr></table>

<A NAME="News"><h2>News</h2></A>
<ul>
<li> [2022.06] One work is accepted by IEEE TAFFC.</li>
<li> [2022.06] One work is accepted by IEEE TIP.</li>
<li> [2022.03] One work is accepted by CVPR 2022.</li>
</ul>
<br />
 
 
<A NAME="Interest"><h2>Research Interest</h2></A>
I work in the field of computer vision and affective computing. Currently, I focus on the following research topics:
<ul>
<li>Facial expression recognition</li>
<li>Semi-supervised learning</li>
<li>Multimodal Learning</li>
</ul>
<br />



 
<A NAME="Education"><h2>Education</h2></A>
<ul>
<li>2018.09-2023.12 &nbsp;&nbsp; Ph.D. in <a href="https://ste.xidian.edu.cn/" target="_blank">School of Telecommunications Engineering</a>, <a href="https://www.xidian.edu.cn/" target="_blank">Xidian University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="https://web.xidian.edu.cn/nnwang/" target="_blank">Nannan Wang</a></li>
<li>2013.09-2017.06 &nbsp;&nbsp; B.E. in <a href="https://www.ise.sdu.edu.cn/" target="_blank">School of Information Science and Engineering</a>, <a href="https://www.sdu.edu.cn/" target="_blank">Shandong University</a>. &nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="https://faculty.sdu.edu.cn/bixianye/zh_CN/index.htm" target="_blank">Xianye Ben</a></li>
</ul>
<br />


<A NAME="Publications"><h2>Publications</h2></A>
<p><b>Conferences</b>: </p><font size="3"> 
<ul>

<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span>[1] <b>Hangyu Li</b>, Nannan Wang*, Xi Yang, Xiaoyu Wang, and Xinbo Gao, 
“Towards Semi-Supervised Deep Facial Expression Recognition with An Adaptive Confidence Margin,” 
In <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2022, pp. 4166-4175. 
 [<a href= "https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_Semi-Supervised_Deep_Facial_Expression_Recognition_With_an_Adaptive_Confidence_CVPR_2022_paper.html" target="_blank">Paper</a>] 
 [<a href= "https://github.com/hangyu94/Ada-CM" target="_blank">Code</a>] 
</ul>
</font>
<br />
 
<p><b>Journals</b>: </p><font size="3"> 
<ul>
 
<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span>[1] <b>Hangyu Li</b>, Nannan Wang*, Xi Yang, and Xinbo Gao, 
“CRS-CONT: A Well-Trained General Encoder for Facial Expression Analysis,” 
<i>IEEE Transactions on Image Processing</i> (<b>IEEE TIP</b>), vol. 31, pp. 4637-4650, 2022.
[<a href= "https://ieeexplore.ieee.org/document/9813458" target="_blank">Paper</a>] 
[<a href= "https://github.com/hangyu94/CRS-CONT" target="_blank">Code</a>]
</span>
</p>
 
<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span>[2] <b>Hangyu Li</b>, Nannan Wang*, Xinpeng Ding, Xi Yang, and Xinbo Gao, 
“Adaptively Learning Facial Expression Representation via C-F Labels and Distillation,” 
<i>IEEE Transactions on Image Processing</i> (<b>IEEE TIP</b>), 
vol. 30, pp. 2016-2028, 2021. 
[<a href= "https://ieeexplore.ieee.org/document/9321757" target="_blank">Paper</a>] 
</span>
</p>
 
<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span>[3] <b>Hangyu Li</b>, Nannan Wang*, Xi Yang, Xiaoyu Wang, and Xinbo Gao, 
“Unconstrained Facial Expression Recognition with No-Reference De-Elements Learning,” 
<i>IEEE Transactions on Affective Computing</i> (<b>IEEE TAFFC</b>), 
Accepted, 2023. 
</span>
</p>
 
<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span>[4] <b>Hangyu Li</b>, Nannan Wang*, Yi Yu, Xi Yang, and Xinbo Gao, 
“LBAN-IL: A Novel Method of High Discriminative Representation for Facial Expression Recognition,” 
<i>Neurocomputing</i> (<b>NEUCOM</b>), 
vol. 432, pp. 159-169, 2021. 
[<a href= "https://www.sciencedirect.com/science/article/pii/S0925231220319767?via%3Dihub" target="_blank">Paper</a>] 
</span>
</p>
 
<p style="text-indent: -1.6rem;margin-left: 0rem;">
<span>[5] <b>Hangyu Li</b>, Nannan Wang*, Mingrui Zhu, Xi Yang, and Xinbo Gao, 
“Recent Advances in Neural Architecture Search: A Survey,” 
<i>Journal of Software</i> (in Chinese),
vol. 33, no. 1, pp. 129-149, 2022.
[<a href= "http://www.jos.org.cn/1000-9825/6306.htm" target="_blank">Paper</a>] 
</span>
</p>
</ul>
<br />


 
<A NAME="Services"><h2>Services</h2></A>
 
<p><b>Reviewer</b>: </p>
<font size="3"> 
<ul>
<li>IEEE Transactions on Image Processing (<b>TIP</b>)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</li>
<li>CVPR 2023</li>
<li>NeurIPS 2023</li>
</ul>
</font>
<br />
 

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>

 
 
</body>
</html>
